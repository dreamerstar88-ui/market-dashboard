"""
News Service v17.1 - Quota: Breaking(2), Macro(2), Index(3), Stock(3)
- Breaking: Top 2 freshest items (any category)
- Others: Filtered by category
"""
import os
import requests
import re
import html
import json
from datetime import datetime
from typing import Optional, List, Dict
try:
    import streamlit as st
except ImportError:
    st = None

# Professional Practice: Don't load .env globally in a way that overrides Cloud Secrets
if not st:
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except ImportError:
        pass


def get_economic_events_for_date(target_date: datetime) -> List[Dict]:
    """íŠ¹ì • ë‚ ì§œì˜ ê²½ì œ ì´ë²¤íŠ¸ ë°˜í™˜"""
    return [
        {"time": "08:00", "country": "ğŸ‡°ğŸ‡·", "event": "ì‚°ì—…ìƒì‚°ì§€ìˆ˜ (MoM)", "importance": "ì¤‘", "forecast": "0.3%", "actual": "0.5%", "previous": "-0.2%"},
        {"time": "08:30", "country": "ğŸ‡¯ğŸ‡µ", "event": "ë„ì¿„ í•µì‹¬ CPI (YoY)", "importance": "ë†’ìŒ", "forecast": "2.4%", "actual": None, "previous": "2.2%"},
        {"time": "10:00", "country": "ğŸ‡¨ğŸ‡³", "event": "ì œì¡°ì—… PMI", "importance": "ë†’ìŒ", "forecast": "50.2", "actual": None, "previous": "49.8%"},
        {"time": "18:00", "country": "ğŸ‡ªğŸ‡º", "event": "ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ (CPI) (YoY)", "importance": "ë†’ìŒ", "forecast": "2.8%", "actual": None, "previous": "2.9%"},
        {"time": "21:30", "country": "ğŸ‡ºğŸ‡¸", "event": "PCE ë¬¼ê°€ì§€ìˆ˜ (Core)", "importance": "ë†’ìŒ", "forecast": "0.2%", "actual": None, "previous": "0.1%"},
        {"time": "22:00", "country": "ğŸ‡ºğŸ‡¸", "event": "ë¯¸ì‹œê°„ ì†Œë¹„ìì‹¬ë¦¬", "importance": "ì¤‘", "forecast": "72.0", "actual": None, "previous": "71.1%"},
        {"time": "22:45", "country": "ğŸ‡ºğŸ‡¸", "event": "ì‹œì¹´ê³  PMI", "importance": "ë‚®ìŒ", "forecast": "40.5", "actual": None, "previous": "36.9"},
    ]


def format_economic_calendar(target_date: datetime) -> str:
    """ê²½ì œ ìº˜ë¦°ë” ë§ˆí¬ë‹¤ìš´ í¬ë§·"""
    events = get_economic_events_for_date(target_date)
    date_str = target_date.strftime("%Y-%m-%d")
    lines = [f"### ğŸ“… {date_str} ì£¼ìš” ê²½ì œ ì§€í‘œ", "", "| ì‹œê°„ | êµ­ê°€ | ì§€í‘œ | ì¤‘ìš”ë„ | ì˜ˆì¸¡ | ì‹¤ì œ | ì´ì „ |", "|:----:|:----:|------|:------:|:----:|:----:|:----:|"]
    for e in events:
        actual = e["actual"] if e["actual"] else "â³"
        imp = "ğŸ”´" if e["importance"] == "ë†’ìŒ" else "ğŸŸ¡" if e["importance"] == "ì¤‘" else "âšª"
        lines.append(f"| {e['time']} | {e['country']} | {e['event']} | {imp} | {e['forecast']} | {actual} | {e['previous']} |")
    
    lines.extend([
        "",
        "---",
        "**ğŸ“Œ ì¤‘ìš”ë„ ë²”ë¡€:** ğŸ”´ ë†’ìŒ | ğŸŸ¡ ì¤‘ê°„ | âšª ë‚®ìŒ",
        "> ğŸ’¡ â³ = ë°œí‘œ ëŒ€ê¸° ì¤‘"
    ])
    return "\n".join(lines)


def categorize_news(title: str) -> int:
    """ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (1:ê±°ì‹œ, 2:ì§€ìˆ˜, 3:ì£¼ì‹)"""
    t = title.lower()
    macro = ['fed', 'rate', 'inflation', 'cpi', 'gdp', 'job', 'economy', 'recession', 'policy', 'treasury', 'yield', 'war', 'oil', 'gold', 'ê¸ˆë¦¬', 'ë¬¼ê°€', 'ì—°ì¤€']
    index = ['s&p', 'nasdaq', 'dow', 'market', 'stocks', 'rally', 'crash', 'bull', 'bear', 'index', 'kospi', 'kosdaq', 'ì§€ìˆ˜', 'ì¦ì‹œ', 'ìƒìŠ¹', 'í•˜ë½', 'futures']
    if any(k in t for k in macro): return 1
    if any(k in t for k in index): return 2
    return 3


def fetch_rss_news(feed_url: str, source_name: str) -> List[Dict]:
    """RSS Parser"""
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
        response = requests.get(feed_url, headers=headers, timeout=10)
        items = re.findall(r'<item>(.*?)</item>', response.text, re.DOTALL)
        news_list = []
        now = datetime.now()
        
        # Increase fetch limit to 30 to ensure we have enough candidates
        for item in items[:30]:
            title_m = re.search(r'<title>(.*?)</title>', item, re.DOTALL)
            link_m = re.search(r'<link>(.*?)</link>', item, re.DOTALL)
            pub_m = re.search(r'<pubDate>(.*?)</pubDate>', item, re.DOTALL)
            
            if title_m:
                t = html.unescape(re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title_m.group(1))).strip()
                t = re.sub(r'<[^>]+>', '', t)
                l = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', link_m.group(1)).strip() if link_m else ""
                
                h_ago = 999
                t_disp = "ìµœê·¼"
                if pub_m:
                    try:
                        pd_str = pub_m.group(1).strip()[:25]
                        dt = datetime.strptime(pd_str, "%a, %d %b %Y %H:%M:%S")
                        
                        # Timezone handling assumption (UTC if +0000)
                        diff = (datetime.utcnow() - dt).total_seconds() / 3600
                        
                        h_ago = diff
                        if diff < 1: t_disp = f"{int(diff*60)}ë¶„ ì „"
                        elif diff < 24: t_disp = f"{int(diff)}ì‹œê°„ ì „"
                        else: t_disp = f"{int(diff/24)}ì¼ ì „"
                    except: pass
                
                news_list.append({
                    "time": t_disp, "source": source_name, "title": t, "link": l,
                    "priority": categorize_news(t), "hours_ago": h_ago
                })
        return news_list
    except: return []


def parse_json_list(text: str) -> List[str]:
    """AIê°€ ë°˜í™˜í•œ í…ìŠ¤íŠ¸ì—ì„œ JSON ë¦¬ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ëŠ” ìœ í‹¸ë¦¬í‹°"""
    if not text: return []
    try:
        # 1. ```json ... ``` ë¸”ë¡ ì œê±° ì‹œë„
        clean_text = text.strip()
        if clean_text.startswith("```"):
            clean_text = re.sub(r'^```[a-z]*\s*', '', clean_text)
            clean_text = re.sub(r'\s*```$', '', clean_text)
        
        # 2. JSON íŒŒì‹±
        return json.loads(clean_text)
    except:
        # 3. ì •ê·œë¸Œë¡œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë§Œ ì¶”ì¶œ ì‹œë„ (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        match = re.search(r'\[.*\]', text, re.DOTALL)
        if match:
            try: return json.loads(match.group())
            except: pass
        return []


class TranslationService:
    """Gemini APIë¥¼ ì´ìš©í•œ ì „ë¬¸ ë²ˆì—­ ì„œë¹„ìŠ¤ (Python-Pro patterns)"""
    
    def __init__(self, api_key: Optional[str]):
        # Clean the API Key (Remove quotes and spaces that often come from TOML/Secrets copy-paste)
        self.api_key = str(api_key).strip().replace('"', '').replace("'", "") if api_key else None
        self.client = None
        self.last_error = None
        if self.api_key and self.api_key != "None":
            try:
                from google import genai
                self.client = genai.Client(api_key=self.api_key)
            except Exception as e:
                self.last_error = f"Library Load Error: {str(e)}"

    def translate_headlines(self, titles: List[str]) -> List[str]:
        """ê¸°ì‚¬ë¥¼ ìœ ë™ì ìœ¼ë¡œ ë²ˆì—­í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
        if not self.api_key:
            self.last_error = "API Key missing"
            return titles
            
        count = len(titles)
        prompt = f"Translate to Korean. Return JSON list. Input: {json.dumps(titles, ensure_ascii=False)}"

        # Models to try in order
        models = ["gemini-2.0-flash-exp", "gemini-1.5-pro", "gemini-1.5-flash"]
        
        # Trial 1: SDK (The most robust way if library is present)
        if self.client:
            for model_name in models:
                try:
                    from google.genai import types
                    response = self.client.models.generate_content(
                        model=model_name,
                        contents=prompt,
                        config=types.GenerateContentConfig(temperature=0.0)
                    )
                    if response.text:
                        result = parse_json_list(response.text)
                        if result:
                            # Success! Ensure 1:1 mapping
                            final_list = titles.copy()
                            for i, r in enumerate(result[:count]): final_list[i] = r
                            return final_list
                except Exception as e:
                    self.last_error = f"SDK {model_name} Error: {str(e)}"
                    print(f"TranslationService: {model_name} failed. {e}")
                    continue # Try next model
        
        # Trial 2: REST Fallback (Direct request v1)
        # Using a very simple prompt to avoid 400s
        try:
            # v1 is more standard for GA models
            headers = {'Content-Type': 'application/json'}
            # Try both standard and latest names
            for m_id in ["gemini-1.5-flash", "gemini-1.5-flash-latest"]:
                url = f"https://generativelanguage.googleapis.com/v1/models/{m_id}:generateContent?key={self.api_key}"
                payload = {"contents": [{"parts": [{"text": prompt}]}]}
                resp = requests.post(url, json=payload, headers=headers, timeout=10)
                if resp.status_code == 200:
                    text = resp.json()["candidates"][0]["content"]["parts"][0]["text"]
                    result = parse_json_list(text)
                    if result:
                        final_list = titles.copy()
                        for i, r in enumerate(result[:count]): final_list[i] = r
                        return final_list
                else:
                    self.last_error = f"REST {m_id} Error {resp.status_code}: {resp.text[:100]}"
        except Exception as e:
            self.last_error = f"Connection Error: {str(e)}"

        return titles


def get_translated_market_news() -> str:
    """ë‰´ìŠ¤ ì¿¼í„° (ì†ë³´2, ê±°ì‹œ2, ì§€ìˆ˜3, ì¢…ëª©3)"""
    sources = [
        ("https://feeds.finance.yahoo.com/rss/2.0/headline?s=^GSPC,^IXIC,^DJI,NVDA,TSLA,AAPL,MSFT&region=US&lang=en-US", "Yahoo Finance"),
        ("https://kr.investing.com/rss/news_25.rss", "Investing.com"), 
        ("https://kr.investing.com/rss/stock.rss", "Investing.com"),
        ("https://news.google.com/rss/topics/CAAqJggBCiSJQVVCQzFBUWcyTWpCb1kzbG9hWGIwS2hVcGQzQnliMWRpYXlnQVAB?hl=en-US&gl=US&ceid=US:en", "Google News")
    ]
    
    all_items = []
    seen = set()
    for url, src in sources:
        for item in fetch_rss_news(url, src):
            if item["title"] not in seen:
                seen.add(item["title"])
                all_items.append(item)
    
    all_items.sort(key=lambda x: x["hours_ago"])
    
    # Selection logic remains same for consistency
    breaking_quota = 2
    breaking = all_items[:breaking_quota]
    pool = all_items[breaking_quota:]
    buckets = {1: [], 2: [], 3: []}
    for item in pool: buckets[item["priority"]].append(item)
    quotas = {1: 2, 2: 3, 3: 3}
    final = breaking
    for cat in [1, 2, 3]:
        count = quotas[cat]
        final.extend(buckets[cat][:count])
        buckets[cat] = buckets[cat][count:]
    
    if len(final) < 10:
        rem = []
        for cat in [1, 2, 3]: rem.extend(buckets[cat])
        rem.sort(key=lambda x: x["hours_ago"])
        final.extend(rem[:10 - len(final)])
    
    final.sort(key=lambda x: x["hours_ago"])
    final = final[:10]
    
    # --- Professional Translation (Brute-Force Source Control) ---
    api_key = None
    source = "Not Found"
    detected_keys = []
    
    # Priority 1: Manual Session Bypass (Highest)
    if st and "manual_gemini_key" in st.session_state and st.session_state["manual_gemini_key"]:
        api_key = st.session_state["manual_gemini_key"]
        source = "Sidebar Manual Input"
        
    # Priority 2: Streamlit Secrets
    if not api_key and st:
        try:
            detected_keys = list(st.secrets.keys())
            possible_names = ["GEMINI_API_KEY", "gemini_api_key", "GEMINI_KEY", "Gemini_API"]
            for name in possible_names:
                if name in st.secrets:
                    val = st.secrets[name]
                    if val and val != "None":
                        api_key = val
                        source = f"Streamlit Secrets ({name})"
                        break
        except Exception:
            pass
            
    # Priority 3: OS Environment
    if not api_key:
        env_key = os.getenv("GEMINI_API_KEY")
        if env_key:
            if env_key.endswith("nRjSY"):
                source = "OS Environment (POISONED - OLD KEY DETECTED)"
                api_key = None 
            else:
                api_key = env_key
                source = "OS Environment (.env or System)"
    
    if api_key:
        # Final clean
        api_key = str(api_key).strip().replace('"', '').replace("'", "")
    
    titles = [n["title"] for n in final]
    service = TranslationService(api_key)
    translated = service.translate_headlines(titles)
    
    # Professional Formatter
    lines = ["### ğŸ“° ì‹œì¥ ë‰´ìŠ¤ (ì‹¤ì‹œê°„)", ""]
    
    # Diagnostic Status (Safe Key Verification)
    if api_key:
        key_tag = f"`{api_key[:5]}...{api_key[-5:]}`"
    else:
        key_tag = "`Missing / Blocked`"
        
    success_count = sum(1 for i, t in enumerate(translated) if t != titles[i])
    if success_count == 0:
        lines.append(f"> ğŸ§ª **Diagnostic**: {source}")
        lines.append(f"> ğŸ“‚ **Secrets Keys Found**: `{detected_keys if detected_keys else 'None'}`")
        if api_key:
            lines.append(f"> ğŸ› ï¸ **Key Check**: {key_tag}")
            lines.append(f"> âŒ **ë²ˆì—­ ì‹¤íŒ¨**: `{service.last_error if service.last_error else 'Unknown error'}`")
        else:
            lines.append("> ğŸš¨ **ì•Œë¦¼**: ìœ íš¨í•œ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ 'Secrets Keys Found'ì— `GEMINI_API_KEY`ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    elif success_count < len(titles):
        lines.append(f"> ğŸ”„ **ë²ˆì—­ ìƒíƒœ**: {success_count}/{len(titles)} í•­ëª© ì™„ë£Œ (Source: {source})")
    else:
        lines.append(f"> âœ… **ë‰´ìŠ¤ ë²ˆì—­ ì™„ë£Œ** (Source: {source})")
    lines.append("")

    for i, item in enumerate(final):
        t = translated[i]
        badge = "ğŸ”¥" if i < 2 and item["hours_ago"] < 3 else "ğŸ“¢"
        lines.append(f"**{badge} [{item['time']}] {item['source']}** [ğŸ”—]({item['link']})  \n&nbsp;&nbsp;&nbsp;&nbsp;{t}\n")
        
    return "\n".join(lines)


def get_translated_economic_events(target_date: Optional[datetime] = None) -> str:
    if target_date is None: target_date = datetime.now()
    return format_economic_calendar(target_date)



def get_translated_economic_events(target_date: Optional[datetime] = None) -> str:
    if target_date is None: target_date = datetime.now()
    return format_economic_calendar(target_date)
