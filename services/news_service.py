"""
News Service v17.1 - Quota: Breaking(2), Macro(2), Index(3), Stock(3)
- Breaking: Top 2 freshest items (any category)
- Others: Filtered by category
"""
import os
import requests
import re
import html
import json
from datetime import datetime
from typing import Optional, List, Dict
from dotenv import load_dotenv

load_dotenv(override=True)


def get_economic_events_for_date(target_date: datetime) -> List[Dict]:
    """ÌäπÏ†ï ÎÇ†ÏßúÏùò Í≤ΩÏ†ú Ïù¥Î≤§Ìä∏ Î∞òÌôò"""
    return [
        {"time": "08:00", "country": "üá∞üá∑", "event": "ÏÇ∞ÏóÖÏÉùÏÇ∞ÏßÄÏàò (MoM)", "importance": "Ï§ë", "forecast": "0.3%", "actual": "0.5%", "previous": "-0.2%"},
        {"time": "08:30", "country": "üáØüáµ", "event": "ÎèÑÏøÑ ÌïµÏã¨ CPI (YoY)", "importance": "ÎÜíÏùå", "forecast": "2.4%", "actual": None, "previous": "2.2%"},
        {"time": "10:00", "country": "üá®üá≥", "event": "Ï†úÏ°∞ÏóÖ PMI", "importance": "ÎÜíÏùå", "forecast": "50.2", "actual": None, "previous": "49.8%"},
        {"time": "18:00", "country": "üá™üá∫", "event": "ÏÜåÎπÑÏûêÎ¨ºÍ∞ÄÏßÄÏàò (CPI) (YoY)", "importance": "ÎÜíÏùå", "forecast": "2.8%", "actual": None, "previous": "2.9%"},
        {"time": "21:30", "country": "üá∫üá∏", "event": "PCE Î¨ºÍ∞ÄÏßÄÏàò (Core)", "importance": "ÎÜíÏùå", "forecast": "0.2%", "actual": None, "previous": "0.1%"},
        {"time": "22:00", "country": "üá∫üá∏", "event": "ÎØ∏ÏãúÍ∞Ñ ÏÜåÎπÑÏûêÏã¨Î¶¨", "importance": "Ï§ë", "forecast": "72.0", "actual": None, "previous": "71.1%"},
        {"time": "22:45", "country": "üá∫üá∏", "event": "ÏãúÏπ¥Í≥† PMI", "importance": "ÎÇÆÏùå", "forecast": "40.5", "actual": None, "previous": "36.9"},
    ]


def format_economic_calendar(target_date: datetime) -> str:
    """Í≤ΩÏ†ú Ï∫òÎ¶∞Îçî ÎßàÌÅ¨Îã§Ïö¥ Ìè¨Îß∑"""
    events = get_economic_events_for_date(target_date)
    date_str = target_date.strftime("%Y-%m-%d")
    lines = [f"### üìÖ {date_str} Ï£ºÏöî Í≤ΩÏ†ú ÏßÄÌëú", "", "| ÏãúÍ∞Ñ | Íµ≠Í∞Ä | ÏßÄÌëú | Ï§ëÏöîÎèÑ | ÏòàÏ∏° | Ïã§Ï†ú | Ïù¥Ï†Ñ |", "|:----:|:----:|------|:------:|:----:|:----:|:----:|"]
    for e in events:
        actual = e["actual"] if e["actual"] else "‚è≥"
        imp = "üî¥" if e["importance"] == "ÎÜíÏùå" else "üü°" if e["importance"] == "Ï§ë" else "‚ö™"
        lines.append(f"| {e['time']} | {e['country']} | {e['event']} | {imp} | {e['forecast']} | {actual} | {e['previous']} |")
    
    lines.extend([
        "",
        "---",
        "**üìå Ï§ëÏöîÎèÑ Î≤îÎ°Ä:** üî¥ ÎÜíÏùå | üü° Ï§ëÍ∞Ñ | ‚ö™ ÎÇÆÏùå",
        "> üí° ‚è≥ = Î∞úÌëú ÎåÄÍ∏∞ Ï§ë"
    ])
    return "\n".join(lines)


def categorize_news(title: str) -> int:
    """Îâ¥Ïä§ Ïπ¥ÌÖåÍ≥†Î¶¨ Î∂ÑÎ•ò (1:Í±∞Ïãú, 2:ÏßÄÏàò, 3:Ï£ºÏãù)"""
    t = title.lower()
    macro = ['fed', 'rate', 'inflation', 'cpi', 'gdp', 'job', 'economy', 'recession', 'policy', 'treasury', 'yield', 'war', 'oil', 'gold', 'Í∏àÎ¶¨', 'Î¨ºÍ∞Ä', 'Ïó∞Ï§Ä']
    index = ['s&p', 'nasdaq', 'dow', 'market', 'stocks', 'rally', 'crash', 'bull', 'bear', 'index', 'kospi', 'kosdaq', 'ÏßÄÏàò', 'Ï¶ùÏãú', 'ÏÉÅÏäπ', 'ÌïòÎùΩ', 'futures']
    if any(k in t for k in macro): return 1
    if any(k in t for k in index): return 2
    return 3


def fetch_rss_news(feed_url: str, source_name: str) -> List[Dict]:
    """RSS Parser"""
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
        response = requests.get(feed_url, headers=headers, timeout=10)
        items = re.findall(r'<item>(.*?)</item>', response.text, re.DOTALL)
        news_list = []
        now = datetime.now()
        
        # Increase fetch limit to 30 to ensure we have enough candidates
        for item in items[:30]:
            title_m = re.search(r'<title>(.*?)</title>', item, re.DOTALL)
            link_m = re.search(r'<link>(.*?)</link>', item, re.DOTALL)
            pub_m = re.search(r'<pubDate>(.*?)</pubDate>', item, re.DOTALL)
            
            if title_m:
                t = html.unescape(re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title_m.group(1))).strip()
                t = re.sub(r'<[^>]+>', '', t)
                l = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', link_m.group(1)).strip() if link_m else ""
                
                h_ago = 999
                t_disp = "ÏµúÍ∑º"
                if pub_m:
                    try:
                        pd_str = pub_m.group(1).strip()[:25]
                        dt = datetime.strptime(pd_str, "%a, %d %b %Y %H:%M:%S")
                        
                        # Timezone handling assumption (UTC if +0000)
                        diff = (datetime.utcnow() - dt).total_seconds() / 3600
                        
                        h_ago = diff
                        if diff < 1: t_disp = f"{int(diff*60)}Î∂Ñ Ï†Ñ"
                        elif diff < 24: t_disp = f"{int(diff)}ÏãúÍ∞Ñ Ï†Ñ"
                        else: t_disp = f"{int(diff/24)}Ïùº Ï†Ñ"
                    except: pass
                
                news_list.append({
                    "time": t_disp, "source": source_name, "title": t, "link": l,
                    "priority": categorize_news(t), "hours_ago": h_ago
                })
        return news_list
    except: return []


def parse_json_list(text: str) -> List[str]:
    """AIÍ∞Ä Î∞òÌôòÌïú ÌÖçÏä§Ìä∏ÏóêÏÑú JSON Î¶¨Ïä§Ìä∏Îßå Ï∂îÏ∂úÌïòÎäî Ïú†Ìã∏Î¶¨Ìã∞"""
    if not text: return []
    try:
        # 1. ```json ... ``` Î∏îÎ°ù Ï†úÍ±∞ ÏãúÎèÑ
        clean_text = text.strip()
        if clean_text.startswith("```"):
            clean_text = re.sub(r'^```[a-z]*\s*', '', clean_text)
            clean_text = re.sub(r'\s*```$', '', clean_text)
        
        # 2. JSON ÌååÏã±
        return json.loads(clean_text)
    except:
        # 3. Ï†ïÍ∑úÎ∏åÎ°ú Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎßå Ï∂îÏ∂ú ÏãúÎèÑ (ÎßàÏßÄÎßâ ÏàòÎã®)
        match = re.search(r'\[.*\]', text, re.DOTALL)
        if match:
            try: return json.loads(match.group())
            except: pass
        return []


def get_translated_market_news() -> str:
    """Îâ¥Ïä§ ÏøºÌÑ∞ (ÏÜçÎ≥¥2, Í±∞Ïãú2, ÏßÄÏàò3, Ï¢ÖÎ™©3)"""
    sources = [
        ("https://feeds.finance.yahoo.com/rss/2.0/headline?s=^GSPC,^IXIC,^DJI,NVDA,TSLA,AAPL,MSFT&region=US&lang=en-US", "Yahoo Finance"),
        ("https://kr.investing.com/rss/news_25.rss", "Investing.com"), 
        ("https://kr.investing.com/rss/stock.rss", "Investing.com"),
        ("https://news.google.com/rss/topics/CAAqJggBCiSJQVVCQzFBUWcyTWpCb1kzbG9hWGIwS2hVcGQzQnliMWRpYXlnQVAB?hl=en-US&gl=US&ceid=US:en", "Google News")
    ]
    
    all_items = []
    seen = set()
    for url, src in sources:
        for item in fetch_rss_news(url, src):
            if item["title"] not in seen:
                seen.add(item["title"])
                all_items.append(item)
    
    all_items.sort(key=lambda x: x["hours_ago"])
    final = []
    
    breaking_quota = 2
    breaking = all_items[:breaking_quota]
    final.extend(breaking)
    pool = all_items[breaking_quota:]
    
    buckets = {1: [], 2: [], 3: []}
    for item in pool: buckets[item["priority"]].append(item)
    
    quotas = {1: 2, 2: 3, 3: 3}
    for cat in [1, 2, 3]:
        count = quotas[cat]
        selected = buckets[cat][:count]
        final.extend(selected)
        buckets[cat] = buckets[cat][count:]
    
    if len(final) < 10:
        rem = []
        for cat in [1, 2, 3]: rem.extend(buckets[cat])
        rem.sort(key=lambda x: x["hours_ago"])
        final.extend(rem[:10 - len(final)])
    
    final.sort(key=lambda x: x["hours_ago"])
    final = final[:10]
    
    lines = ["### üì∞ ÏãúÏû• Îâ¥Ïä§ (Ïã§ÏãúÍ∞Ñ)", ""]
    
    # --- Translation & Formatting ---
    api_key = os.getenv("GEMINI_API_KEY")
    titles = [n["title"] for n in final]
    translated = titles  
    
    if api_key:
        # Prompt refined for 1:1 mapping and no combination
        prompt = f"""
        Translate each of the following financial headlines into Korean individually.
        Keep them concise and return ONLY a JSON list of exactly {len(titles)} strings in the same order.
        Input: {json.dumps(titles)}
        """
        
        # Strategy 1: SDK (google-genai)
        try:
            from google import genai
            client = genai.Client(api_key=api_key)
            response = client.models.generate_content(
                model="gemini-2.0-flash-exp",
                contents=prompt
            )
            if response.text:
                result = parse_json_list(response.text)
                if result and len(result) > 0: translated = result
        except Exception as e_sdk:
            # Strategy 2: REST API (gemini-1.5-flash)
            try:
                url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
                payload = {"contents": [{"parts": [{"text": prompt}]}]}
                resp = requests.post(url, json=payload, timeout=10)
                if resp.status_code == 200:
                    text = resp.json()["candidates"][0]["content"]["parts"][0]["text"]
                    result = parse_json_list(text)
                    if result and len(result) > 0: translated = result
                else: raise Exception(f"REST 1.5 Code {resp.status_code}")
            except Exception as e_rest1:
                # Strategy 3: REST API (gemini-pro)
                try:
                    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={api_key}"
                    resp = requests.post(url, json={"contents": [{"parts": [{"text": prompt}]}]}, timeout=10)
                    if resp.status_code == 200:
                        text = resp.json()["candidates"][0]["content"]["parts"][0]["text"]
                        result = parse_json_list(text)
                        if result and len(result) > 0: translated = result
                except: pass

    # Range-based loop to ensure all news are shown even if translation count differs
    for i, item in enumerate(final):
        # Use translated text if index exists, else fallback to original title
        t = translated[i] if i < len(translated) else item["title"]
        
        # Add a "üî•" badge for breaking news (top 2 news if really fresh, e.g. < 2 hours)
        badge = "üî•" if i < 2 and item["hours_ago"] < 3 else "üì¢"
        
        line_1 = f"**{badge} [{item['time']}] {item['source']}** [üîó]({item['link']})"
        line_2 = f"&nbsp;&nbsp;&nbsp;&nbsp;{t}"
        lines.append(f"{line_1}  \n{line_2}")
        lines.append("")
        
    return "\n".join(lines)


def get_translated_economic_events(target_date: Optional[datetime] = None) -> str:
    if target_date is None: target_date = datetime.now()
    return format_economic_calendar(target_date)
