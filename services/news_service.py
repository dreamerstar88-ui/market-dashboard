"""
News Service v17.1 - Quota: Breaking(2), Macro(2), Index(3), Stock(3)
- Breaking: Top 2 freshest items (any category)
- Others: Filtered by category
"""
import os
import requests
import re
import html
import json
from datetime import datetime
from typing import Optional, List, Dict
try:
    import streamlit as st
except ImportError:
    st = None

# Professional Practice: Don't load .env globally in a way that overrides Cloud Secrets
if not st:
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except ImportError:
        pass


def get_economic_events_for_date(target_date: datetime) -> List[Dict]:
    """ÌäπÏ†ï ÎÇ†ÏßúÏùò Í≤ΩÏ†ú Ïù¥Î≤§Ìä∏ Î∞òÌôò"""
    return [
        {"time": "08:00", "country": "üá∞üá∑", "event": "ÏÇ∞ÏóÖÏÉùÏÇ∞ÏßÄÏàò (MoM)", "importance": "Ï§ë", "forecast": "0.3%", "actual": "0.5%", "previous": "-0.2%"},
        {"time": "08:30", "country": "üáØüáµ", "event": "ÎèÑÏøÑ ÌïµÏã¨ CPI (YoY)", "importance": "ÎÜíÏùå", "forecast": "2.4%", "actual": None, "previous": "2.2%"},
        {"time": "10:00", "country": "üá®üá≥", "event": "Ï†úÏ°∞ÏóÖ PMI", "importance": "ÎÜíÏùå", "forecast": "50.2", "actual": None, "previous": "49.8%"},
        {"time": "18:00", "country": "üá™üá∫", "event": "ÏÜåÎπÑÏûêÎ¨ºÍ∞ÄÏßÄÏàò (CPI) (YoY)", "importance": "ÎÜíÏùå", "forecast": "2.8%", "actual": None, "previous": "2.9%"},
        {"time": "21:30", "country": "üá∫üá∏", "event": "PCE Î¨ºÍ∞ÄÏßÄÏàò (Core)", "importance": "ÎÜíÏùå", "forecast": "0.2%", "actual": None, "previous": "0.1%"},
        {"time": "22:00", "country": "üá∫üá∏", "event": "ÎØ∏ÏãúÍ∞Ñ ÏÜåÎπÑÏûêÏã¨Î¶¨", "importance": "Ï§ë", "forecast": "72.0", "actual": None, "previous": "71.1%"},
        {"time": "22:45", "country": "üá∫üá∏", "event": "ÏãúÏπ¥Í≥† PMI", "importance": "ÎÇÆÏùå", "forecast": "40.5", "actual": None, "previous": "36.9"},
    ]


def format_economic_calendar(target_date: datetime) -> str:
    """Í≤ΩÏ†ú Ï∫òÎ¶∞Îçî ÎßàÌÅ¨Îã§Ïö¥ Ìè¨Îß∑"""
    events = get_economic_events_for_date(target_date)
    date_str = target_date.strftime("%Y-%m-%d")
    lines = [f"### üìÖ {date_str} Ï£ºÏöî Í≤ΩÏ†ú ÏßÄÌëú", "", "| ÏãúÍ∞Ñ | Íµ≠Í∞Ä | ÏßÄÌëú | Ï§ëÏöîÎèÑ | ÏòàÏ∏° | Ïã§Ï†ú | Ïù¥Ï†Ñ |", "|:----:|:----:|------|:------:|:----:|:----:|:----:|"]
    for e in events:
        actual = e["actual"] if e["actual"] else "‚è≥"
        imp = "üî¥" if e["importance"] == "ÎÜíÏùå" else "üü°" if e["importance"] == "Ï§ë" else "‚ö™"
        lines.append(f"| {e['time']} | {e['country']} | {e['event']} | {imp} | {e['forecast']} | {actual} | {e['previous']} |")
    
    lines.extend([
        "",
        "---",
        "**üìå Ï§ëÏöîÎèÑ Î≤îÎ°Ä:** üî¥ ÎÜíÏùå | üü° Ï§ëÍ∞Ñ | ‚ö™ ÎÇÆÏùå",
        "> üí° ‚è≥ = Î∞úÌëú ÎåÄÍ∏∞ Ï§ë"
    ])
    return "\n".join(lines)


def categorize_news(title: str) -> int:
    """Îâ¥Ïä§ Ïπ¥ÌÖåÍ≥†Î¶¨ Î∂ÑÎ•ò (1:Í±∞Ïãú, 2:ÏßÄÏàò, 3:Ï£ºÏãù)"""
    t = title.lower()
    macro = ['fed', 'rate', 'inflation', 'cpi', 'gdp', 'job', 'economy', 'recession', 'policy', 'treasury', 'yield', 'war', 'oil', 'gold', 'Í∏àÎ¶¨', 'Î¨ºÍ∞Ä', 'Ïó∞Ï§Ä']
    index = ['s&p', 'nasdaq', 'dow', 'market', 'stocks', 'rally', 'crash', 'bull', 'bear', 'index', 'kospi', 'kosdaq', 'ÏßÄÏàò', 'Ï¶ùÏãú', 'ÏÉÅÏäπ', 'ÌïòÎùΩ', 'futures']
    if any(k in t for k in macro): return 1
    if any(k in t for k in index): return 2
    return 3


def fetch_rss_news(feed_url: str, source_name: str) -> List[Dict]:
    """RSS Parser"""
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
        response = requests.get(feed_url, headers=headers, timeout=10)
        items = re.findall(r'<item>(.*?)</item>', response.text, re.DOTALL)
        news_list = []
        now = datetime.now()
        
        # Increase fetch limit to 30 to ensure we have enough candidates
        for item in items[:30]:
            title_m = re.search(r'<title>(.*?)</title>', item, re.DOTALL)
            link_m = re.search(r'<link>(.*?)</link>', item, re.DOTALL)
            pub_m = re.search(r'<pubDate>(.*?)</pubDate>', item, re.DOTALL)
            
            if title_m:
                t = html.unescape(re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title_m.group(1))).strip()
                t = re.sub(r'<[^>]+>', '', t)
                l = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', link_m.group(1)).strip() if link_m else ""
                
                h_ago = 999
                t_disp = "ÏµúÍ∑º"
                if pub_m:
                    try:
                        pd_str = pub_m.group(1).strip()[:25]
                        dt = datetime.strptime(pd_str, "%a, %d %b %Y %H:%M:%S")
                        
                        # Timezone handling assumption (UTC if +0000)
                        diff = (datetime.utcnow() - dt).total_seconds() / 3600
                        
                        h_ago = diff
                        if diff < 1: t_disp = f"{int(diff*60)}Î∂Ñ Ï†Ñ"
                        elif diff < 24: t_disp = f"{int(diff)}ÏãúÍ∞Ñ Ï†Ñ"
                        else: t_disp = f"{int(diff/24)}Ïùº Ï†Ñ"
                    except: pass
                
                news_list.append({
                    "time": t_disp, "source": source_name, "title": t, "link": l,
                    "priority": categorize_news(t), "hours_ago": h_ago
                })
        return news_list
    except: return []


def parse_json_list(text: str) -> List[str]:
    """AIÍ∞Ä Î∞òÌôòÌïú ÌÖçÏä§Ìä∏ÏóêÏÑú JSON Î¶¨Ïä§Ìä∏Îßå Ï∂îÏ∂úÌïòÎäî Ïú†Ìã∏Î¶¨Ìã∞"""
    if not text: return []
    try:
        # 1. ```json ... ``` Î∏îÎ°ù Ï†úÍ±∞ ÏãúÎèÑ
        clean_text = text.strip()
        if clean_text.startswith("```"):
            clean_text = re.sub(r'^```[a-z]*\s*', '', clean_text)
            clean_text = re.sub(r'\s*```$', '', clean_text)
        
        # 2. JSON ÌååÏã±
        return json.loads(clean_text)
    except:
        # 3. Ï†ïÍ∑úÎ∏åÎ°ú Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎßå Ï∂îÏ∂ú ÏãúÎèÑ (ÎßàÏßÄÎßâ ÏàòÎã®)
        match = re.search(r'\[.*\]', text, re.DOTALL)
        if match:
            try: return json.loads(match.group())
            except: pass
        return []


class TranslationService:
    """Gemini APIÎ•º Ïù¥Ïö©Ìïú Ï†ÑÎ¨∏ Î≤àÏó≠ ÏÑúÎπÑÏä§ (Python-Pro patterns)"""
    
    def __init__(self, api_key: Optional[str]):
        # Clean the API Key (Remove quotes and spaces that often come from TOML/Secrets copy-paste)
        self.api_key = str(api_key).strip().replace('"', '').replace("'", "") if api_key else None
        self.client = None
        self.last_error = None
        if self.api_key and self.api_key != "None":
            try:
                from google import genai
                self.client = genai.Client(api_key=self.api_key)
            except Exception as e:
                self.last_error = f"Library Load Error: {str(e)}"

    def translate_headlines(self, titles: List[str]) -> List[str]:
        """Í∏∞ÏÇ¨Î•º Ïú†ÎèôÏ†ÅÏúºÎ°ú Î≤àÏó≠ÌïòÏó¨ Î¶¨Ïä§Ìä∏Î°ú Î∞òÌôò"""
        if not self.api_key:
            self.last_error = "API Key missing"
            return titles
            
        count = len(titles)
        prompt = f"Translate to Korean. Return JSON list. Input: {json.dumps(titles, ensure_ascii=False)}"

        # Models to try in order
        models = ["gemini-2.0-flash-exp", "gemini-1.5-pro", "gemini-1.5-flash"]
        
        # Trial 1: SDK (The most robust way if library is present)
        if self.client:
            for model_name in models:
                try:
                    from google.genai import types
                    response = self.client.models.generate_content(
                        model=model_name,
                        contents=prompt,
                        config=types.GenerateContentConfig(temperature=0.0)
                    )
                    if response.text:
                        result = parse_json_list(response.text)
                        if result:
                            # Success! Ensure 1:1 mapping
                            final_list = titles.copy()
                            for i, r in enumerate(result[:count]): final_list[i] = r
                            return final_list
                except Exception as e:
                    self.last_error = f"SDK {model_name} Error: {str(e)}"
                    print(f"TranslationService: {model_name} failed. {e}")
                    continue # Try next model
        
        # Trial 2: REST Fallback (Direct request v1beta)
        # Using a very simple prompt to avoid 400s
        try:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={self.api_key}"
            payload = {"contents": [{"parts": [{"text": prompt}]}]}
            resp = requests.post(url, json=payload, timeout=10)
            if resp.status_code == 200:
                text = resp.json()["candidates"][0]["content"]["parts"][0]["text"]
                result = parse_json_list(text)
                if result:
                    final_list = titles.copy()
                    for i, r in enumerate(result[:count]): final_list[i] = r
                    return final_list
            else:
                self.last_error = f"REST Error {resp.status_code}: {resp.text[:100]}"
        except Exception as e:
            self.last_error = f"Connection Error: {str(e)}"

        return titles


def get_translated_market_news() -> str:
    """Îâ¥Ïä§ ÏøºÌÑ∞ (ÏÜçÎ≥¥2, Í±∞Ïãú2, ÏßÄÏàò3, Ï¢ÖÎ™©3)"""
    sources = [
        ("https://feeds.finance.yahoo.com/rss/2.0/headline?s=^GSPC,^IXIC,^DJI,NVDA,TSLA,AAPL,MSFT&region=US&lang=en-US", "Yahoo Finance"),
        ("https://kr.investing.com/rss/news_25.rss", "Investing.com"), 
        ("https://kr.investing.com/rss/stock.rss", "Investing.com"),
        ("https://news.google.com/rss/topics/CAAqJggBCiSJQVVCQzFBUWcyTWpCb1kzbG9hWGIwS2hVcGQzQnliMWRpYXlnQVAB?hl=en-US&gl=US&ceid=US:en", "Google News")
    ]
    
    all_items = []
    seen = set()
    for url, src in sources:
        for item in fetch_rss_news(url, src):
            if item["title"] not in seen:
                seen.add(item["title"])
                all_items.append(item)
    
    all_items.sort(key=lambda x: x["hours_ago"])
    
    # Selection logic remains same for consistency
    breaking_quota = 2
    breaking = all_items[:breaking_quota]
    pool = all_items[breaking_quota:]
    buckets = {1: [], 2: [], 3: []}
    for item in pool: buckets[item["priority"]].append(item)
    quotas = {1: 2, 2: 3, 3: 3}
    final = breaking
    for cat in [1, 2, 3]:
        count = quotas[cat]
        final.extend(buckets[cat][:count])
        buckets[cat] = buckets[cat][count:]
    
    if len(final) < 10:
        rem = []
        for cat in [1, 2, 3]: rem.extend(buckets[cat])
        rem.sort(key=lambda x: x["hours_ago"])
        final.extend(rem[:10 - len(final)])
    
    final.sort(key=lambda x: x["hours_ago"])
    final = final[:10]
    
    # --- Professional Translation (Strict Source Control) ---
    api_key = None
    source = "Not Found"
    
    if st:
        try:
            if "GEMINI_API_KEY" in st.secrets:
                api_key = st.secrets["GEMINI_API_KEY"]
                source = "Streamlit Secrets"
        except Exception:
            pass
            
    if not api_key:
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key:
            source = "OS Environment (Possible .env conflict)"
    
    if api_key:
        # Final clean
        api_key = str(api_key).strip().replace('"', '').replace("'", "")
    
    titles = [n["title"] for n in final]
    service = TranslationService(api_key)
    translated = service.translate_headlines(titles)
    
    # Professional Formatter
    lines = ["### üì∞ ÏãúÏû• Îâ¥Ïä§ (Ïã§ÏãúÍ∞Ñ)", ""]
    
    # Diagnostic Status (Safe Key Verification)
    if api_key:
        key_tag = f"`{api_key[:5]}...{api_key[-5:]}`"
    else:
        key_tag = "`Missing`"
        
    success_count = sum(1 for i, t in enumerate(translated) if t != titles[i])
    if success_count == 0 and api_key:
        lines.append(f"> üõ†Ô∏è **Key Check**: {key_tag} (Source: {source})")
        lines.append(f"> ‚ùå **Î≤àÏó≠ Ïã§Ìå®**: `{service.last_error if service.last_error else 'Unknown error'}`")
    elif success_count < len(titles):
        lines.append(f"> üîÑ **Î≤àÏó≠ ÏÉÅÌÉú**: {success_count}/{len(titles)} Ìï≠Î™© ÏôÑÎ£å (Source: {source})")
    else:
        lines.append(f"> ‚úÖ **Îâ¥Ïä§ Î≤àÏó≠ ÏôÑÎ£å** (Source: {source})")
    lines.append("")

    for i, item in enumerate(final):
        t = translated[i]
        badge = "üî•" if i < 2 and item["hours_ago"] < 3 else "üì¢"
        lines.append(f"**{badge} [{item['time']}] {item['source']}** [üîó]({item['link']})  \n&nbsp;&nbsp;&nbsp;&nbsp;{t}\n")
        
    return "\n".join(lines)


def get_translated_economic_events(target_date: Optional[datetime] = None) -> str:
    if target_date is None: target_date = datetime.now()
    return format_economic_calendar(target_date)



def get_translated_economic_events(target_date: Optional[datetime] = None) -> str:
    if target_date is None: target_date = datetime.now()
    return format_economic_calendar(target_date)
