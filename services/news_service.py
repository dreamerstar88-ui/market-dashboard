"""
News Service v17.1 - Quota: Breaking(2), Macro(2), Index(3), Stock(3)
- Breaking: Top 2 freshest items (any category)
- Others: Filtered by category
"""
import os
import requests
import re
import html
import json
from datetime import datetime
from typing import Optional, List, Dict
try:
    import streamlit as st
except ImportError:
    st = None

# Professional Practice: Don't load .env globally in a way that overrides Cloud Secrets
if not st:
    try:
        from dotenv import load_dotenv
        load_dotenv(override=True)
    except ImportError:
        pass


def get_economic_events_for_date(target_date: datetime) -> List[Dict]:
    """íŠ¹ì • ë‚ ì§œì˜ ê²½ì œ ì´ë²¤íŠ¸ ë°˜í™˜"""
    return [
        {"time": "08:00", "country": "ğŸ‡°ğŸ‡·", "event": "ì‚°ì—…ìƒì‚°ì§€ìˆ˜ (MoM)", "importance": "ì¤‘", "forecast": "0.3%", "actual": "0.5%", "previous": "-0.2%"},
        {"time": "08:30", "country": "ğŸ‡¯ğŸ‡µ", "event": "ë„ì¿„ í•µì‹¬ CPI (YoY)", "importance": "ë†’ìŒ", "forecast": "2.4%", "actual": None, "previous": "2.2%"},
        {"time": "10:00", "country": "ğŸ‡¨ğŸ‡³", "event": "ì œì¡°ì—… PMI", "importance": "ë†’ìŒ", "forecast": "50.2", "actual": None, "previous": "49.8%"},
        {"time": "18:00", "country": "ğŸ‡ªğŸ‡º", "event": "ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ (CPI) (YoY)", "importance": "ë†’ìŒ", "forecast": "2.8%", "actual": None, "previous": "2.9%"},
        {"time": "21:30", "country": "ğŸ‡ºğŸ‡¸", "event": "PCE ë¬¼ê°€ì§€ìˆ˜ (Core)", "importance": "ë†’ìŒ", "forecast": "0.2%", "actual": None, "previous": "0.1%"},
        {"time": "22:00", "country": "ğŸ‡ºğŸ‡¸", "event": "ë¯¸ì‹œê°„ ì†Œë¹„ìì‹¬ë¦¬", "importance": "ì¤‘", "forecast": "72.0", "actual": None, "previous": "71.1%"},
        {"time": "22:45", "country": "ğŸ‡ºğŸ‡¸", "event": "ì‹œì¹´ê³  PMI", "importance": "ë‚®ìŒ", "forecast": "40.5", "actual": None, "previous": "36.9"},
    ]


def format_economic_calendar(target_date: datetime) -> str:
    """ê²½ì œ ìº˜ë¦°ë” ë§ˆí¬ë‹¤ìš´ í¬ë§·"""
    events = get_economic_events_for_date(target_date)
    date_str = target_date.strftime("%Y-%m-%d")
    lines = [f"### ğŸ“… {date_str} ì£¼ìš” ê²½ì œ ì§€í‘œ", "", "| ì‹œê°„ | êµ­ê°€ | ì§€í‘œ | ì¤‘ìš”ë„ | ì˜ˆì¸¡ | ì‹¤ì œ | ì´ì „ |", "|:----:|:----:|------|:------:|:----:|:----:|:----:|"]
    for e in events:
        actual = e["actual"] if e["actual"] else "â³"
        imp = "ğŸ”´" if e["importance"] == "ë†’ìŒ" else "ğŸŸ¡" if e["importance"] == "ì¤‘" else "âšª"
        lines.append(f"| {e['time']} | {e['country']} | {e['event']} | {imp} | {e['forecast']} | {actual} | {e['previous']} |")
    
    lines.extend([
        "",
        "---",
        "**ğŸ“Œ ì¤‘ìš”ë„ ë²”ë¡€:** ğŸ”´ ë†’ìŒ | ğŸŸ¡ ì¤‘ê°„ | âšª ë‚®ìŒ",
        "> ğŸ’¡ â³ = ë°œí‘œ ëŒ€ê¸° ì¤‘"
    ])
    return "\n".join(lines)


def categorize_news(title: str) -> int:
    """ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (1:ê±°ì‹œ, 2:ì§€ìˆ˜, 3:ì£¼ì‹)"""
    t = title.lower()
    macro = ['fed', 'rate', 'inflation', 'cpi', 'gdp', 'job', 'economy', 'recession', 'policy', 'treasury', 'yield', 'war', 'oil', 'gold', 'ê¸ˆë¦¬', 'ë¬¼ê°€', 'ì—°ì¤€']
    index = ['s&p', 'nasdaq', 'dow', 'market', 'stocks', 'rally', 'crash', 'bull', 'bear', 'index', 'kospi', 'kosdaq', 'ì§€ìˆ˜', 'ì¦ì‹œ', 'ìƒìŠ¹', 'í•˜ë½', 'futures']
    if any(k in t for k in macro): return 1
    if any(k in t for k in index): return 2
    return 3


def fetch_rss_news(feed_url: str, source_name: str) -> List[Dict]:
    """RSS Parser"""
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
        response = requests.get(feed_url, headers=headers, timeout=10)
        items = re.findall(r'<item>(.*?)</item>', response.text, re.DOTALL)
        news_list = []
        now = datetime.now()
        
        # Increase fetch limit to 30 to ensure we have enough candidates
        for item in items[:30]:
            title_m = re.search(r'<title>(.*?)</title>', item, re.DOTALL)
            link_m = re.search(r'<link>(.*?)</link>', item, re.DOTALL)
            pub_m = re.search(r'<pubDate>(.*?)</pubDate>', item, re.DOTALL)
            
            if title_m:
                t = html.unescape(re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title_m.group(1))).strip()
                t = re.sub(r'<[^>]+>', '', t)
                l = re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', link_m.group(1)).strip() if link_m else ""
                
                h_ago = 999
                t_disp = "ìµœê·¼"
                if pub_m:
                    try:
                        pd_str = pub_m.group(1).strip()[:25]
                        dt = datetime.strptime(pd_str, "%a, %d %b %Y %H:%M:%S")
                        
                        # Timezone handling assumption (UTC if +0000)
                        diff = (datetime.utcnow() - dt).total_seconds() / 3600
                        
                        h_ago = diff
                        if diff < 1: t_disp = f"{int(diff*60)}ë¶„ ì „"
                        elif diff < 24: t_disp = f"{int(diff)}ì‹œê°„ ì „"
                        else: t_disp = f"{int(diff/24)}ì¼ ì „"
                    except: pass
                
                news_list.append({
                    "time": t_disp, "source": source_name, "title": t, "link": l,
                    "priority": categorize_news(t), "hours_ago": h_ago
                })
        return news_list
    except: return []


def parse_json_list(text: str) -> List[str]:
    """AIê°€ ë°˜í™˜í•œ í…ìŠ¤íŠ¸ì—ì„œ JSON ë¦¬ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ëŠ” ìœ í‹¸ë¦¬í‹°"""
    if not text: return []
    try:
        # 1. ```json ... ``` ë¸”ë¡ ì œê±° ì‹œë„
        clean_text = text.strip()
        if clean_text.startswith("```"):
            clean_text = re.sub(r'^```[a-z]*\s*', '', clean_text)
            clean_text = re.sub(r'\s*```$', '', clean_text)
        
        # 2. JSON íŒŒì‹±
        return json.loads(clean_text)
    except:
        # 3. ì •ê·œë¸Œë¡œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë§Œ ì¶”ì¶œ ì‹œë„ (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        match = re.search(r'\[.*\]', text, re.DOTALL)
        if match:
            try: return json.loads(match.group())
            except: pass
        return []


class TranslationService:
    """Gemini APIë¥¼ ì´ìš©í•œ ì „ë¬¸ ë²ˆì—­ ì„œë¹„ìŠ¤ (Python-Pro patterns)"""
    
    def __init__(self, api_key: Optional[str]):
        self.api_key = api_key
        self.client = None
        self.last_error = ""
        self.available_models = []
        if api_key:
            try:
                from google import genai
                self.client = genai.Client(api_key=api_key)
            except Exception:
                pass

    def discover_models(self) -> List[str]:
        """ì¡°íšŒê°€ ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ìˆ˜ë™ìœ¼ë¡œ íƒìƒ‰"""
        if not self.api_key: return []
        try:
            url = f"https://generativelanguage.googleapis.com/v1/models?key={self.api_key}"
            resp = requests.get(url, timeout=5)
            if resp.status_code == 200:
                models = resp.json().get("models", [])
                return [m["name"].replace("models/", "") for m in models]
        except:
            pass
        return []

    def translate_headlines(self, titles: List[str]) -> List[str]:
        """ê¸°ì‚¬ë¥¼ ìœ ë™ì ìœ¼ë¡œ ë²ˆì—­í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
        if not self.api_key:
            self.last_error = "API Key missing"
            return titles
            
        count = len(titles)
        # Prompt Engineering for Strict Korean Only
        prompt = f"Translate these headlines to Korean. Return a flat JSON list of strings. Do not include original English text. Input: {json.dumps(titles, ensure_ascii=False)}"

        # Models to try in order (Custom Config: gemini-2.0-flash is standard)
        models = ["gemini-2.0-flash", "gemini-1.5-flash"]
        # Trial 1: SDK (The most robust way if library is present)
        if self.client:
            try:
                from google.genai import types
                # Use the latest confirmed working model
                model_name = "gemini-2.0-flash" 
                response = self.client.models.generate_content(
                    model=model_name,
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        temperature=0.1,
                    )
                )
                if response.text:
                    result = parse_json_list(response.text)
                    if result:
                        final_list = titles.copy()
                        for i, r in enumerate(result[:count]): final_list[i] = r
                        return final_list
            except Exception as e:
                self.last_error = f"SDK Error: {str(e)}"
                print(f"TranslationService: {model_name} failed. {e}")
        
        # Trial 2: REST Fallback (Direct request v1 & v1beta)
        try:
            headers = {'Content-Type': 'application/json'}
            # Try combinations based on confirmed 'Available Models' list
            trials = [
                ("v1beta", "gemini-2.0-flash"),
                ("v1beta", "gemini-1.5-flash"),
                ("v1", "gemini-1.5-flash"),
            ]
            
            for ver, m_id in trials:
                url = f"https://generativelanguage.googleapis.com/{ver}/models/{m_id}:generateContent?key={self.api_key}"
                payload = {"contents": [{"parts": [{"text": prompt}]}]}
                try:
                    resp = requests.post(url, json=payload, headers=headers, timeout=10)
                    if resp.status_code == 200:
                        text = resp.json()["candidates"][0]["content"]["parts"][0]["text"]
                        result = parse_json_list(text)
                        if result:
                            final_list = titles.copy()
                            for i, r in enumerate(result[:count]): final_list[i] = r
                            return final_list
                    else:
                        self.last_error = f"REST {ver}/{m_id} Error {resp.status_code}"
                except Exception as e:
                    self.last_error = f"REST {ver}/{m_id} Conn Error: {str(e)}"
                    continue
        except Exception as e:
            self.last_error = f"Global REST Error: {str(e)}"

        return titles


def get_translated_market_news() -> str:
    """ë‰´ìŠ¤ ì¿¼í„° (ì†ë³´2, ê±°ì‹œ2, ì§€ìˆ˜3, ì¢…ëª©3)"""
    sources = [
        ("https://feeds.finance.yahoo.com/rss/2.0/headline?s=^GSPC,^IXIC,^DJI,NVDA,TSLA,AAPL,MSFT&region=US&lang=en-US", "Yahoo Finance"),
        ("https://kr.investing.com/rss/news_25.rss", "Investing.com"), 
        ("https://kr.investing.com/rss/stock.rss", "Investing.com"),
        ("https://news.google.com/rss/topics/CAAqJggBCiSJQVVCQzFBUWcyTWpCb1kzbG9hWGIwS2hVcGQzQnliMWRpYXlnQVAB?hl=en-US&gl=US&ceid=US:en", "Google News")
    ]
    
    all_items = []
    seen = set()
    for url, src in sources:
        for item in fetch_rss_news(url, src):
            if item["title"] not in seen:
                seen.add(item["title"])
                all_items.append(item)
    
    all_items.sort(key=lambda x: x["hours_ago"])
    
    # Selection logic remains same for consistency
    breaking_quota = 2
    breaking = all_items[:breaking_quota]
    pool = all_items[breaking_quota:]
    buckets = {1: [], 2: [], 3: []}
    for item in pool: buckets[item["priority"]].append(item)
    quotas = {1: 2, 2: 3, 3: 3}
    final = breaking
    for cat in [1, 2, 3]:
        count = quotas[cat]
        final.extend(buckets[cat][:count])
        buckets[cat] = buckets[cat][count:]
    
    if len(final) < 10:
        rem = []
        for cat in [1, 2, 3]: rem.extend(buckets[cat])
        rem.sort(key=lambda x: x["hours_ago"])
        final.extend(rem[:10 - len(final)])
    
    final.sort(key=lambda x: x["hours_ago"])
    final = final[:10]
    
    # --- Professional Translation (Brute-Force Source Control) ---
    api_key = None
    source = "Not Found"
    detected_keys = []
    
    # Priority 1: Manual Session Bypass (Highest)
    if st and "manual_gemini_key" in st.session_state and st.session_state["manual_gemini_key"]:
        api_key = st.session_state["manual_gemini_key"]
        source = "Sidebar Manual Input"
        
    # Priority 2: Streamlit Secrets
    if not api_key and st:
        try:
            detected_keys = list(st.secrets.keys())
            possible_names = ["GEMINI_API_KEY", "gemini_api_key", "GEMINI_KEY", "Gemini_API"]
            for name in possible_names:
                if name in st.secrets:
                    val = st.secrets[name]
                    if val and val != "None":
                        api_key = val
                        source = f"Streamlit Secrets ({name})"
                        break
        except Exception:
            pass
            
    # Priority 3: OS Environment
    if not api_key:
        # Fallback to OS environment
        env_key = os.getenv("GEMINI_API_KEY")
        if env_key:
            api_key = env_key
            # Detect potentially poisoned key (old one)
            if env_key.endswith("nRjSY"):
                source = "OS Environment (OLD KEY DETECTED - 400 ERRORS LIKELY)"
            else:
                source = "OS Environment (.env or System)"
    
    if api_key:
        # Final clean
        api_key = str(api_key).strip().replace('"', '').replace("'", "")
    
    titles = [n["title"] for n in final]
    service = TranslationService(api_key)
    translated = service.translate_headlines(titles)
    
    # Professional Formatter
    lines = ["### ğŸ“° ì‹œì¥ ë‰´ìŠ¤ (ì‹¤ì‹œê°„)", ""]
    
    # Diagnostic Status (Safe Key Verification)
    if api_key:
        key_tag = f"`{api_key[:5]}...{api_key[-5:]}`"
    else:
        key_tag = "`Missing / Blocked`"
        
    success_count = sum(1 for i, t in enumerate(translated) if t != titles[i])
    
    # Clean UI: Use expander for logs if anything is less than perfect
    if success_count < len(titles) or source != "Streamlit Secrets":
        with st.expander("ğŸ› ï¸ ì‹œìŠ¤í…œ ì§„ë‹¨ ë¡œê·¸ (ë²ˆì—­ ë¬¸ì œ ë°œìƒ ì‹œ í™•ì¸)", expanded=(success_count == 0)):
            st.write(f"**Diagnostic**: {source}")
            st.write(f"**Secrets Detection**: `{detected_keys if detected_keys else 'None'}`")
            if api_key:
                st.write(f"**Key Check**: `{api_key[:5]}...{api_key[-5:]}`")
                st.write(f"**Last Error**: `{service.last_error if service.last_error else 'None'}`")
                models = service.discover_models()
                if models: st.write(f"**Available Models**: `{', '.join(models[:5])}...`")
            else:
                st.error("ğŸš¨ ìœ íš¨í•œ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env ë˜ëŠ” Secretsë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    
    if success_count == len(titles):
        lines.append(f"> âœ… **ë‰´ìŠ¤ ë²ˆì—­ ì™„ë£Œ** (Gemini 2.0)")
    elif success_count > 0:
        lines.append(f"> ğŸ”„ **ë²ˆì—­ ìƒíƒœ**: {success_count}/{len(titles)} í•­ëª© ì™„ë£Œ")
    else:
        lines.append("> â³ **ë²ˆì—­ ëŒ€ê¸° ì¤‘**: API ì„¤ì •ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    lines.append("")

    for i, item in enumerate(final):
        t = translated[i]
        # Logic to detect if it was actually translated
        is_translated = (t != item["title"])
        badge = "ğŸ”¥" if i < 2 and item["hours_ago"] < 3 else "ğŸ“¢"
        trans_badge = " ğŸ¤–" if is_translated else ""
        
        lines.append(f"**{badge} [{item['time']}] {item['source']}**{trans_badge} [ğŸ”—]({item['link']})  \n&nbsp;&nbsp;&nbsp;&nbsp;{t}\n")
        
    return "\n".join(lines)


def get_translated_economic_events(target_date: Optional[datetime] = None) -> str:
    if target_date is None: target_date = datetime.now()
    return format_economic_calendar(target_date)



def get_translated_economic_events(target_date: Optional[datetime] = None) -> str:
    if target_date is None: target_date = datetime.now()
    return format_economic_calendar(target_date)
